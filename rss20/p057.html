<html> 
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />  
<head>  
<meta name="citation_title" content="Rethinking Robustness Assessment: Adversarial Attacks on Learning-based Quadrupedal Locomotion Controllers" />  
<meta name="citation_author" content="Fan Shi, Chong Zhang, Takahiro Miki, Joonho Lee, Marco Hutter, Stelian Coros" />  
<meta name="citation_publication_date" content="2024/07/15" />  
<meta name="citation_conference_title" content="Robotics: Science and Systems XX" />  
<meta name="citation_isbn" content="979-8-9902848-0-7" />  
<meta name="citation_volume" content="20" />  
<meta name="citation_pdf_url" content="http://www.roboticsproceedings.org/rss20/p057.pdf" />  
<title>Robotics: Science and Systems XX - Online Proceedings</title>  
<link type="text/css" rel="stylesheet" href="../style.css">  
<!--[if IE 5]> 
<link type="text/css" rel="stylesheet" href="../ie5.css"> 
<![endif]-->  
<!--[if IE 6]> 
<link type="text/css" rel="stylesheet" href="../ie6.css"> 
<![endif]-->  
</head>  
<body>  
<div class="menu">  
<%include="menu-fragment.html"%> 
</div>  
<div class="content">  
  
<h1>Robotics: Science and Systems XX</h1>  
<h3>Rethinking Robustness Assessment: Adversarial Attacks on Learning-based Quadrupedal Locomotion Controllers</h3> 
<i>Fan Shi, Chong Zhang, Takahiro Miki, Joonho Lee, Marco Hutter, Stelian Coros</i><br> 
<p>  
<b>Abstract:</b>  
</p><p style="text-align: justify;">  
Legged locomotion has recently achieved remarkable success with the progress of machine learning techniques, especially deep reinforcement learning (RL). Controllers employing neural networks have demonstrated empirical and qualitative robustness against real-world uncertainties, including sensor noise and external perturbations. However, formally investigating the vulnerabilities of these locomotion controllers remains a challenge. This difficulty arises from the requirement to pinpoint vulnerabilities across a long-tailed distribution within a high-dimensional, temporally sequential space. As a first step towards quantitative verification, we propose a computational method that leverages sequential adversarial attacks to identify weaknesses in learned locomotion controllers. Our research demonstrates that, even state-of-the-art robust controllers can fail significantly under well-designed, low-magnitude adversarial sequence. Through experiments in simulation and on the real robot, we validate our approach's effectiveness, and we illustrate how the results it generates can be used to robustify the original policy and offer valuable insights into the safety of these black-box policies.
</p>  
<p>  
<b>Download:</b> <a href="p057.pdf" target="_blank" onclick="_gaq.push(['_trackEvent','rss10/p057.pdf','PDF',this.href]);"><img src="../icon-pdf.png" border=0></a> 
</p>  
<p>  
<b>Bibtex:</b>  
<pre>  
@INPROCEEDINGS{Shi-RSS-24, 
    AUTHOR    = {Fan Shi, Chong Zhang, Takahiro Miki, Joonho Lee, Marco Hutter, Stelian Coros}, 
    TITLE     = {{Rethinking Robustness Assessment: Adversarial Attacks on Learning-based Quadrupedal Locomotion Controllers}}, 
    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, 
    YEAR      = {2024}, 
    ADDRESS   = {Delft, Netherlands}, 
    MONTH     = {July}, 
    DOI       = {10.15607/RSS.2024.XX.057} 
} 
  
</pre>  
</p>  
  
</div>  
<div class="analyt"> 
<%include="analyt-fragment.html"%> 
</div> 
</body>  
</html> 

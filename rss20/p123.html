<html> 
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />  
<head>  
<meta name="citation_title" content="Learning Manipulation by Predicting Interaction" />  
<meta name="citation_author" content="Jia Zeng, Qingwen Bu, Bangjun Wang, Wenke Xia, Li Chen, Hao Dong, Haoming Song, Dong Wang, Di Hu, Ping Luo, Heming Cui, Bin Zhao, Xuelong Li, Yu Qiao, Hongyang Li" />  
<meta name="citation_publication_date" content="2024/07/15" />  
<meta name="citation_conference_title" content="Robotics: Science and Systems XX" />  
<meta name="citation_isbn" content="979-8-9902848-0-7" />  
<meta name="citation_volume" content="20" />  
<meta name="citation_pdf_url" content="http://www.roboticsproceedings.org/rss20/p123.pdf" />  
<title>Robotics: Science and Systems XX - Online Proceedings</title>  
<link type="text/css" rel="stylesheet" href="../style.css">  
<!--[if IE 5]> 
<link type="text/css" rel="stylesheet" href="../ie5.css"> 
<![endif]-->  
<!--[if IE 6]> 
<link type="text/css" rel="stylesheet" href="../ie6.css"> 
<![endif]-->  
</head>  
<body>  
<div class="menu">  
<%include="menu-fragment.html"%> 
</div>  
<div class="content">  
  
<h1>Robotics: Science and Systems XX</h1>  
<h3>Learning Manipulation by Predicting Interaction</h3> 
<i>Jia Zeng, Qingwen Bu, Bangjun Wang, Wenke Xia, Li Chen, Hao Dong, Haoming Song, Dong Wang, Di Hu, Ping Luo, Heming Cui, Bin Zhao, Xuelong Li, Yu Qiao, Hongyang Li</i><br> 
<p>  
<b>Abstract:</b>  
</p><p style="text-align: justify;">  
Representation learning approaches for robotic manipulation have boomed in recent years. Due to the scarcity of in-domain robot data, prevailing methodologies tend to leverage large-scale human video datasets to extract generalizable features for visuomotor policy learning. Despite the progress achieved, prior endeavors disregard the interactive dynamics that capture behavior patterns and physical interaction during the manipulation process, resulting in an inadequate understanding of the relationship between objects and the environment. To this end, we propose a general pre-training pipeline that learns Manipulation by Predicting the Interaction (MPI) and enhances the visual representation. Given a pair of keyframes representing the initial and final states, along with language instructions, our algorithm predicts the transition frame and detects the interaction object, respectively. These two learning objectives achieve superior comprehension towards “how-to-interact” and “where-to-interact”. We conduct a comprehensive evaluation of four challenging robotic tasks. The experimental results demonstrate that MPI exhibits remarkable improvement by 10% to 64% compared with previous state-of-the-art in real-world robot platforms as well as simulation environments. Code and checkpoints are 
 publicly shared at https://github.com/OpenDriveLab/MPI.
</p>  
<p>  
<b>Download:</b> <a href="p123.pdf" target="_blank" onclick="_gaq.push(['_trackEvent','rss10/p123.pdf','PDF',this.href]);"><img src="../icon-pdf.png" border=0></a> 
</p>  
<p>  
<b>Bibtex:</b>  
<pre>  
@INPROCEEDINGS{Zeng-RSS-24, 
    AUTHOR    = {Jia Zeng, Qingwen Bu, Bangjun Wang, Wenke Xia, Li Chen, Hao Dong, Haoming Song, Dong Wang, Di Hu, Ping Luo, Heming Cui, Bin Zhao, Xuelong Li, Yu Qiao, Hongyang Li}, 
    TITLE     = {{Learning Manipulation by Predicting Interaction}}, 
    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, 
    YEAR      = {2024}, 
    ADDRESS   = {Delft, Netherlands}, 
    MONTH     = {July}, 
    DOI       = {10.15607/RSS.2024.XX.123} 
} 
  
</pre>  
</p>  
  
</div>  
<div class="analyt"> 
<%include="analyt-fragment.html"%> 
</div> 
</body>  
</html> 

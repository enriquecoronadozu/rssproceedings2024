<html> 
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />  
<head>  
<meta name="citation_title" content="ScrewMimic: Bimanual Imitation from Human Videos with Screw Space Projection" />  
<meta name="citation_author" content="Arpit Bahety, Priyanka Mandikal, Ben Abbatematteo, Roberto Martín-Martín" />  
<meta name="citation_publication_date" content="2024/07/15" />  
<meta name="citation_conference_title" content="Robotics: Science and Systems XX" />  
<meta name="citation_isbn" content="979-8-9902848-0-7" />  
<meta name="citation_volume" content="20" />  
<meta name="citation_pdf_url" content="http://www.roboticsproceedings.org/rss20/p078.pdf" />  
<title>Robotics: Science and Systems XX - Online Proceedings</title>  
<link type="text/css" rel="stylesheet" href="../style.css">  
<!--[if IE 5]> 
<link type="text/css" rel="stylesheet" href="../ie5.css"> 
<![endif]-->  
<!--[if IE 6]> 
<link type="text/css" rel="stylesheet" href="../ie6.css"> 
<![endif]-->  
</head>  
<body>  
<div class="menu">  
<%include="menu-fragment.html"%> 
</div>  
<div class="content">  
  
<h1>Robotics: Science and Systems XX</h1>  
<h3>ScrewMimic: Bimanual Imitation from Human Videos with Screw Space Projection</h3> 
<i>Arpit Bahety, Priyanka Mandikal, Ben Abbatematteo, Roberto Martín-Martín</i><br> 
<p>  
<b>Abstract:</b>  
</p><p style="text-align: justify;">  
Bimanual manipulation is a longstanding challenge in robotics due to the large number of degrees of freedom and the strict spatial and temporal synchronization required to generate meaningful behavior. Humans learn bimanual manipulation skills by watching other humans and by refining their abilities through play. In this work, we aim to enable robots to learn bimanual manipulation behaviors from human video demonstrations and fine-tune them through interaction. Inspired by seminal work in psychology and biomechanics, we propose modeling the interaction between two hands as a serial kinematic linkage — as a screw motion, in particular, that we use to define a new action space for bimanual manipulation: screw actions. We introduce SCREWMIMIC, a framework that leverages this novel action representation to facilitate learning from human demonstration and self-supervised policy fine-tuning. Our experiments demonstrate that SCREWMIMIC is able to learn several complex bimanual behaviors from a single human video demonstration, and that it outperforms baselines that interpret demonstrations and fine-tune directly in the original space of motion of both arms.
</p>  
<p>  
<b>Download:</b> <a href="p078.pdf" target="_blank" onclick="_gaq.push(['_trackEvent','rss10/p078.pdf','PDF',this.href]);"><img src="../icon-pdf.png" border=0></a> 
</p>  
<p>  
<b>Bibtex:</b>  
<pre>  
@INPROCEEDINGS{Bahety-RSS-24, 
    AUTHOR    = {Arpit Bahety, Priyanka Mandikal, Ben Abbatematteo, Roberto Martín-Martín}, 
    TITLE     = {{ScrewMimic: Bimanual Imitation from Human Videos with Screw Space Projection}}, 
    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, 
    YEAR      = {2024}, 
    ADDRESS   = {Delft, Netherlands}, 
    MONTH     = {July}, 
    DOI       = {10.15607/RSS.2024.XX.078} 
} 
  
</pre>  
</p>  
  
</div>  
<div class="analyt"> 
<%include="analyt-fragment.html"%> 
</div> 
</body>  
</html> 

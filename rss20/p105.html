<html> 
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />  
<head>  
<meta name="citation_title" content="Demonstrating Language-Grounded Motion Controller" />  
<meta name="citation_author" content="Ravi Tejwani, Chengyuan Ma, Paco Gomez-Paz, Paolo Bonato, Haruhiko Asada" />  
<meta name="citation_publication_date" content="2024/07/15" />  
<meta name="citation_conference_title" content="Robotics: Science and Systems XX" />  
<meta name="citation_isbn" content="979-8-9902848-0-7" />  
<meta name="citation_volume" content="20" />  
<meta name="citation_pdf_url" content="http://www.roboticsproceedings.org/rss20/p105.pdf" />  
<title>Robotics: Science and Systems XX - Online Proceedings</title>  
<link type="text/css" rel="stylesheet" href="../style.css">  
<!--[if IE 5]> 
<link type="text/css" rel="stylesheet" href="../ie5.css"> 
<![endif]-->  
<!--[if IE 6]> 
<link type="text/css" rel="stylesheet" href="../ie6.css"> 
<![endif]-->  
</head>  
<body>  
<div class="menu">  
<%include="menu-fragment.html"%> 
</div>  
<div class="content">  
  
<h1>Robotics: Science and Systems XX</h1>  
<h3>Demonstrating Language-Grounded Motion Controller</h3> 
<i>Ravi Tejwani, Chengyuan Ma, Paco Gomez-Paz, Paolo Bonato, Haruhiko Asada</i><br> 
<p>  
<b>Abstract:</b>  
</p><p style="text-align: justify;">  
Recent advancements have enabled human-robot collaboration through physical assistance and verbal guidance. However, limitations persist in coordinating robots' physical motions and speech in response to real-time changes in human behavior during collaborative contact tasks.
 We first derive principles from analyzing physical therapists' movements and speech during patient exercises. These principles are translated into control objectives to: 1) guide users through trajectories, 2) control motion and speech pace to align completion times with varying user cooperation, and 3) dynamically paraphrase speech along the trajectory.
 We then propose a Language Controller that synchronizes motion and speech, modulating both based on user cooperation. 
 Experiments with 12 users show the Language Controller successfully aligns motion and speech compared to baselines. This provides a framework for fluent human-robot collaboration.
</p>  
<p>  
<b>Download:</b> <a href="p105.pdf" target="_blank" onclick="_gaq.push(['_trackEvent','rss10/p105.pdf','PDF',this.href]);"><img src="../icon-pdf.png" border=0></a> 
</p>  
<p>  
<b>Bibtex:</b>  
<pre>  
@INPROCEEDINGS{Tejwani-RSS-24, 
    AUTHOR    = {Ravi Tejwani, Chengyuan Ma, Paco Gomez-Paz, Paolo Bonato, Haruhiko Asada}, 
    TITLE     = {{Demonstrating Language-Grounded Motion Controller}}, 
    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, 
    YEAR      = {2024}, 
    ADDRESS   = {Delft, Netherlands}, 
    MONTH     = {July}, 
    DOI       = {10.15607/RSS.2024.XX.105} 
} 
  
</pre>  
</p>  
  
</div>  
<div class="analyt"> 
<%include="analyt-fragment.html"%> 
</div> 
</body>  
</html> 
